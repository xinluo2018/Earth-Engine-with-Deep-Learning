{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"models.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPWfwEGTbZWvklHT+zuBoHj"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"jiPGGUDZCvhi","colab_type":"code","colab":{}},"source":["# mount on google drive\n","from google.colab import drive\n","drive.mount('/content/drive/')\n","# go to your work patch\n","import os\n","os.chdir(\"/content/drive/My Drive/Earth-Engine-with-Deep-Learning\")\n","#!ls\n","# !nvidia-smi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7LSFgDdL_4NP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1599441111811,"user_tz":-480,"elapsed":1716,"user":{"displayName":"Xin Luo","photoUrl":"","userId":"06301970496892076570"}},"outputId":"3e539f16-dff6-43b1-e9b4-21cfffda8891"},"source":["%%writefile models/models.py\n","\n","try:\n","    %tensorflow_version 2.x\n","except Exception:\n","    pass\n","import tensorflow as tf\n","\n","############## U-Net\n","###  Define the downsample function\n","##   Conv2D+BN+ReLU\n","def downsample(filters, size, apply_batchnorm=True):\n","    initializer = tf.random_normal_initializer(0., 0.02)\n","    result = tf.keras.Sequential()\n","    result.add(\n","      tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n","                             kernel_initializer=initializer, use_bias=False))\n","    if apply_batchnorm:\n","        result.add(tf.keras.layers.BatchNormalization())\n","#     result.add(tf.keras.layers.LeakyReLU())\n","    result.add(tf.keras.layers.ReLU())\n","    return result\n","\n","### Define the upsample function\n","##  TransposeConv2D+BN+ReLU\n","def upsample(filters, size, apply_dropout=False):\n","    initializer = tf.random_normal_initializer(0., 0.02)\n","    result = tf.keras.Sequential()\n","    result.add(\n","    tf.keras.layers.Conv2DTranspose(filters, size, strides=2,\n","                                    padding='same',\n","                                    kernel_initializer=initializer,\n","                                    use_bias=False))\n","    result.add(tf.keras.layers.BatchNormalization())\n","    if apply_dropout:\n","        result.add(tf.keras.layers.Dropout(0.5))\n","    result.add(tf.keras.layers.ReLU())\n","    return result\n","\n","## Simple U-Net\n","def UNet(input_shape, nclasses=2):\n","    ## encoder of the U-Net\n","    (img_height, img_width, img_channel) = input_shape\n","    down_stack = [\n","        downsample(12, 3), # outp: (bs, img_height/2, img_width/2, 32)\n","        downsample(24, 3), # (bs, img_height/4, img_width/4, 64)\n","        downsample(48, 3), # (bs, img_height/8, img_width/8, 128)\n","        downsample(96, 3), # (bs, img_height/16, img_width/16, 256)\n","        downsample(96, 3), # (bs, img_height/32, img_width/32, 512)\n","        # downsample(96, 3), # (bs, img_height/64, img_width/64, 512)\n","        # downsample(96, 3), # (bs, img_height/128, img_width/128, 512)\n","    ]\n","\n","    ## decoder of the U-Net\n","    up_stack = [\n","        # upsample(96, 3), # outp: (bs, img_height/64, img_width/64, 1024)\n","        # upsample(96, 3), # (bs, img_height/32, img_width/32, 1024)\n","        upsample(96, 3), # (bs, img_height/16, img_width/16, 1024)\n","        upsample(48, 3), # (bs, img_height/8, img_width/8, 512)\n","        upsample(24, 3), # (bs, img_height/4, img_width/4, 256)\n","        upsample(12, 3), # (bs, img_height/2, img_width/2, 128)\n","    ]\n","\n","    initializer = tf.random_normal_initializer(0., 0.02)\n","    \n","    # define the input and output tensors\n","    inputs = tf.keras.layers.Input(shape=[img_height, img_width, img_channel])\n","    if nclasses == 2:\n","        last = tf.keras.layers.Conv2DTranspose(1, 3,\n","                            strides=2,\n","                            padding='same',\n","                            kernel_initializer=initializer,\n","                            activation= 'sigmoid')  ## \n","    else:\n","        last = tf.keras.layers.Conv2DTranspose(nclasses, 3,\n","                            strides=2,\n","                            padding='same',\n","                            kernel_initializer=initializer,\n","                            activation= 'softmax')  ##\n","    concat = tf.keras.layers.Concatenate()    \n","    x = inputs\n","    # Downsampling through the model\n","    skips = []   # reserve the output of medium output of the encoder network \n","    for down in down_stack:\n","        x = down(x)\n","        skips.append(x)\n","    skips = reversed(skips[:-1])  #  \n","    # Upsampling and establishing the skip connections\n","    for up, skip in zip(up_stack, skips):\n","        x = up(x)\n","        x = concat([x, skip])\n","    x = last(x)\n","    return tf.keras.Model(inputs=inputs, outputs=x)\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Overwriting models/models.py\n"],"name":"stdout"}]}]}
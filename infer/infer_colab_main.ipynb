{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"infer_colab_main.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1YKv7cJl1t3KZKo912D3xZrr5okdBOfFh","authorship_tag":"ABX9TyOSGe2qwd71aTQi2jzodcKV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"B3WRnnSKYTtj","colab_type":"text"},"source":["### **This notebook perform automatical extraction of the impervious cover of each Landsat image from 1986-2020**\n","##### Step 1: Obtain the Landsat image data (tfrecord) for impervious prediction.\n","##### Step 2: Prediction with the pretrained model\n","##### Step 3: Write the result into Google Cloud Storage and copy the corresponding .json file from google drive to google cloud storage.\n","##### Step 4: Upload the result (tfrecord) and .json files to the Earth Engine."]},{"cell_type":"code","metadata":{"id":"rA541BVSYTBG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1601014324432,"user_tz":-480,"elapsed":1176,"user":{"displayName":"Xin Luo","photoUrl":"","userId":"06301970496892076570"}},"outputId":"0b503983-90e1-48ca-bea8-7f9265a446c4"},"source":["## Mount on google drive\n","from google.colab import drive\n","drive.mount('/content/drive/')\n","# Cloud authentication.\n","from google.colab import auth\n","auth.authenticate_user()\n"],"execution_count":27,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"gjoZNlUcY4kR","colab_type":"text"},"source":["### **We use Tensorflow 2.2.0 here!**"]},{"cell_type":"code","metadata":{"id":"BCBsls1mYq4y","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1601014326234,"user_tz":-480,"elapsed":1011,"user":{"displayName":"Xin Luo","photoUrl":"","userId":"06301970496892076570"}},"outputId":"8cfb1664-292a-414e-e825-3931c4b6b34e"},"source":["# !pip install tensorflow==2.2.0\n","import tensorflow as tf\n","print(tf.__version__)"],"execution_count":28,"outputs":[{"output_type":"stream","text":["2.3.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"O48E9zBvYJQR","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1601014327581,"user_tz":-480,"elapsed":910,"user":{"displayName":"Xin Luo","photoUrl":"","userId":"06301970496892076570"}}},"source":["\n","import os\n","os.chdir(\"/content/drive/My Drive/Earth-Engine-with-Deep-Learning\")\n","import time\n","import json\n","from utils import imgShow"],"execution_count":29,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iPulXy0kpPOe","colab_type":"text"},"source":["### **Note: the pretrained model is trained with tensorflow 2.2.0.**"]},{"cell_type":"code","metadata":{"id":"_KqeWregO43B","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1601014389861,"user_tz":-480,"elapsed":1681,"user":{"displayName":"Xin Luo","photoUrl":"","userId":"06301970496892076570"}}},"source":["## Super-parameter: \n","## Data (Google Drive)---> Result(Google Cloud Storage) ---> Result (Earth Engine)\n","####################################################\n","##  Google Cloud Storage: path for result writer \n","Project = 'my-project-20200813'\n","Bucket = 'earth-engine-bucket-1'\n","result_gs_dir = 'gs://' + Bucket + '/prediction_impervious_sz/'\n","\n","#### Google Drive: the pretrained model and collected Landsat image (tfrecord).\n","model_path = '/content/drive/My Drive/Earth-Engine-with-Deep-Learning/models/pretrain/unet_MSMT_train_50epoch_CEloss_nosiyAug/model'\n","data_folder = '/content/drive/My Drive/EE_Image/Landsat_image_sz'\n","# Landsat image (.tfrecord) list and the corresponding .json file list.\n","os.chdir(data_folder)\n","filesList = !ls -1\n","FilesList_img = [s for s in filesList if '.tfrecord.gz' in s]\n","FilesList_json = [s for s in filesList if '.json' in s]\n","#### load the pre-trained model\n","model_pretrain = tf.keras.models.load_model(model_path)\n","\n","#### Earth Engine: the path for result (.TFRecord and .json) uploading \n","ee_output_folder = 'users/xin_luo/Impervious_Mapping_SZ/result'\n","\n","## Data features\n","bands_l5 = bands_l7 = ['B1', 'B2', 'B3', 'B4', 'B5', 'B7']\n","bands_l8 = ['B2', 'B3', 'B4', 'B5', 'B6', 'B7']  # determine the bands to be collected\n","## Patch size: Kernel_size + Kernel_buffer\n","kernel_size = [208, 208]\n","kernel_buffer = [48, 48]   # left buffer + right buffer = 48, the same to up and down\n","buffered_shape = [kernel_size[0]+kernel_buffer[0], kernel_size[1]+kernel_buffer[1]]\n"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z-TGdRTXPOTe","colab_type":"code","colab":{}},"source":["date_years = ['1986','1987','1988','1989','1990','1991','1992','1993','1994',\\\n","              '1995','1996','1997','1998','1999','2000','2001','2002','2003',\\\n","              '2004','2005','2006','2007','2008','2009','2010','2011','2012',\\\n","              '2013','2014','2015','2016','2017','2018','2019','2020']\n","date_years_l5 = ['1986','1987','1988','1989','1990','1991','1992','1993',\\\n","                 '1994','1995','1996','1997','1998','1999','2000','2001',\\\n","                 '2002','2003','2004','2005','2006','2007','2008','2009',\\\n","                 '2010','2011']\n","date_years_l7 = ['2012']\n","date_years_l8 = ['2013','2014','2015','2016','2017','2018','2019','2020']\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rIGu3V2_PUTn","colab_type":"code","colab":{}},"source":["## the selected bands corresponding to Landsat image (Landsat 5,7,and8). \n","def getBands(date_year):\n","    '''\n","    input: the date(year) of the landsat image\n","    ouput: the and bands selection \n","    '''\n","    if date_year in date_years_l5+date_years_l7:\n","        bands = bands_l5\n","    elif date_year in date_years_l8:\n","        bands = bands_l8\n","    return bands\n","\n","## functions used to parse the .tfrecord file\n","def parse_image(example_proto):\n","    return tf.io.parse_single_example(example_proto, featuresDict)\n","\n","def toTensor(inputs):\n","    inputsList = [inputs.get(key) for key in bands]\n","    stacked = tf.stack(inputsList, axis=0)\n","    stacked = tf.transpose(stacked, [1, 2, 0])\n","    return stacked\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CDTQKTuMTf0T","colab_type":"code","colab":{}},"source":["for date_year in date_years:\n","    print(date_year)\n","    os.chdir(data_folder)\n","    ### 1.Super parameters\n","    ## define feature dictionary\n","    bands = getBands(date_year)\n","    imageColumns = [tf.io.FixedLenFeature(shape=buffered_shape, dtype=tf.float32) \n","                    for k in bands]\n","    featuresDict = dict(zip(bands, imageColumns))    # 用于tfrecord文件中数据描述的字典\n","    ## .TFRecord image and the .json file.\n","    landsat_img = [img for img in FilesList_img if date_year in img]\n","    landsat_json = [json for json in FilesList_json if date_year in json][0]\n","    ## obtain number of patches with the .json file \n","    jsonText = !cat {landsat_json}\n","    mixer = json.loads(jsonText.nlstr)\n","    patches = mixer['totalPatches']\n","    ## Google Cloud Storage directory to write prediction result \n","    result_gs_path = result_gs_dir + 'Imper_' + date_year + '.TFRecord'\n","    ### 2.Create a dataset from the TFRecord file(s) in Cloud Storage.  \n","    \n","    imageDataset = tf.data.TFRecordDataset(landsat_img, compression_type='GZIP')\n","    imageDataset = imageDataset.map(parse_image, num_parallel_calls=5)\n","    imageDataset = imageDataset.map(toTensor).batch(1)\n","    ### 3.Prediction\n","    predictions = model_pretrain.predict(imageDataset, steps=patches, verbose=1)\n","    ### 4.Write the prediction result to Google Cloud Storage\n","    writer = tf.io.TFRecordWriter(result_gs_path)\n","    i_patch = 0\n","    for predPatch in predictions:\n","        # print('Writing patch ' + str(i_patch) + '...')\n","        predPatch = predPatch[      # clip the overlay region\n","            kernel_buffer[0]//2:kernel_buffer[0]//2+kernel_size[0], \n","            kernel_buffer[1]//2:kernel_buffer[1]//2+kernel_size[1]\n","            ]\n","        # Creat an example\n","        example = tf.train.Example(\n","        features=tf.train.Features(\n","            feature={\n","            'impervious': tf.train.Feature(\n","                float_list=tf.train.FloatList(\n","                    value=predPatch.flatten()))\n","            }\n","        )\n","        )\n","        # Write the example.\n","        writer.write(example.SerializeToString())\n","        i_patch += 1\n","    writer.close()\n","    ### 5.Upload .json file from google drive to google storage\n","    !gsutil -m cp -r {landsat_json} {result_gs_dir}\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M59SlPn_Pqp3","colab_type":"code","colab":{}},"source":["## Authenticate to Earth Engine\n","import ee\n","ee.Authenticate()\n","ee.Initialize()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T4QnE4U8XxW7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":191},"executionInfo":{"status":"ok","timestamp":1601014530875,"user_tz":-480,"elapsed":7796,"user":{"displayName":"Xin Luo","photoUrl":"","userId":"06301970496892076570"}},"outputId":"8c45e83f-8759-416e-a7d8-2f3b99c92eb0"},"source":["# !pip install oauth2client==3.0.0\n","# upload both the .TFRecord file and .json file from google storage to the earth engine.\n","for date_year in date_years:\n","    print(date_year)\n","    ## result (.TFRecord, .json) path in the Google Cloud Storage\n","    result_gs_path = result_gs_dir + 'Imper_' + date_year + '.TFRecord'\n","    landsat_json = [json for json in FilesList_json if date_year in json][0]\n","    jsonFile_gs_path = 'gs://' + Bucket+ '/prediction_impervious_sz/' + landsat_json\n","    # upload path of the Earth Engine\n","    ee_output_image = ee_output_folder + '/' + 'Imper_' + date_year\n","    ## upload\n","    !earthengine upload image --asset_id={ee_output_image} {result_gs_path} {jsonFile_gs_path}\n"],"execution_count":36,"outputs":[{"output_type":"stream","text":["1986\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","non-resource variables are not supported in the long term\n","Running command using Cloud API.  Set --no-use_cloud_api to go back to using the API\n","\n","I0925 06:15:26.763422 140314904721280 discovery.py:894] URL being requested: GET https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/algorithms?prettyPrint=false&alt=json\n","I0925 06:15:28.635452 140314904721280 discovery.py:894] URL being requested: POST https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/image:import?alt=json\n","Started upload task with ID: 2NVGB64K4R3HKVGWKSV7OYMV\n"],"name":"stdout"}]}]}
{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"model.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMiEdSOkNyjkTkRE8XeG0bS"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"8uHBVmYQbH-F","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":125},"executionInfo":{"status":"ok","timestamp":1599312452843,"user_tz":-480,"elapsed":17677,"user":{"displayName":"Xin Luo","photoUrl":"","userId":"06301970496892076570"}},"outputId":"9ea754f7-402e-4d5c-f317-9c2e99c98163"},"source":["## Mount on google drive\n","from google.colab import drive\n","drive.mount('/content/drive/')\n","\n","## to the work directory\n","import os\n","work_dir = \"/content/drive/My Drive/Earth-Engine-with-Deep-Learning/trainer/ai_platform_package\"\n","os.chdir(work_dir)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GVEW271ja2wk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1599312457406,"user_tz":-480,"elapsed":1078,"user":{"displayName":"Xin Luo","photoUrl":"","userId":"06301970496892076570"}},"outputId":"ddb8e985-fa43-4d64-eb50-eed3de69a2e5"},"source":["## model building\n","%%writefile model.py\n","\n","import tensorflow as tf\n","\n","############## U-Net\n","###  Define the downsample function\n","##   Conv2D+BN+ReLU\n","def downsample(filters, size, apply_batchnorm=True):\n","    initializer = tf.random_normal_initializer(0., 0.02)\n","    result = tf.keras.Sequential()\n","    result.add(\n","      tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n","                             kernel_initializer=initializer, use_bias=False))\n","    if apply_batchnorm:\n","        result.add(tf.keras.layers.BatchNormalization())\n","#     result.add(tf.keras.layers.LeakyReLU())\n","    result.add(tf.keras.layers.ReLU())\n","    return result\n","\n","### Define the upsample function\n","##  TransposeConv2D+BN+ReLU\n","def upsample(filters, size, apply_dropout=False):\n","    initializer = tf.random_normal_initializer(0., 0.02)\n","    result = tf.keras.Sequential()\n","    result.add(\n","    tf.keras.layers.Conv2DTranspose(filters, size, strides=2,\n","                                    padding='same',\n","                                    kernel_initializer=initializer,\n","                                    use_bias=False))\n","    result.add(tf.keras.layers.BatchNormalization())\n","    if apply_dropout:\n","        result.add(tf.keras.layers.Dropout(0.5))\n","    result.add(tf.keras.layers.ReLU())\n","    return result\n","\n","## Simple U-Net\n","def UNet(input_shape, nclasses=2):\n","    ## encoder of the U-Net\n","    (img_height, img_width, img_channel) = input_shape\n","    down_stack = [\n","        downsample(12, 3), # outp: (bs, img_height/2, img_width/2, 32)\n","        downsample(24, 3), # (bs, img_height/4, img_width/4, 64)\n","        downsample(48, 3), # (bs, img_height/8, img_width/8, 128)\n","        downsample(96, 3), # (bs, img_height/16, img_width/16, 256)\n","        downsample(96, 3), # (bs, img_height/32, img_width/32, 512)\n","        # downsample(96, 3), # (bs, img_height/64, img_width/64, 512)\n","        # downsample(96, 3), # (bs, img_height/128, img_width/128, 512)\n","    ]\n","\n","    ## decoder of the U-Net\n","    up_stack = [\n","        # upsample(96, 3), # outp: (bs, img_height/64, img_width/64, 1024)\n","        # upsample(96, 3), # (bs, img_height/32, img_width/32, 1024)\n","        upsample(96, 3), # (bs, img_height/16, img_width/16, 1024)\n","        upsample(48, 3), # (bs, img_height/8, img_width/8, 512)\n","        upsample(24, 3), # (bs, img_height/4, img_width/4, 256)\n","        upsample(12, 3), # (bs, img_height/2, img_width/2, 128)\n","    ]\n","\n","    initializer = tf.random_normal_initializer(0., 0.02)\n","    \n","    # define the input and output tensors\n","    inputs = tf.keras.layers.Input(shape=[img_height, img_width, img_channel])\n","    if nclasses == 2:\n","        last = tf.keras.layers.Conv2DTranspose(1, 3,\n","                            strides=2,\n","                            padding='same',\n","                            kernel_initializer=initializer,\n","                            activation= 'sigmoid')  ## \n","    else:\n","        last = tf.keras.layers.Conv2DTranspose(nclasses, 3,\n","                            strides=2,\n","                            padding='same',\n","                            kernel_initializer=initializer,\n","                            activation= 'softmax')  ##\n","    concat = tf.keras.layers.Concatenate()    \n","    x = inputs\n","    # Downsampling through the model\n","    skips = []   # reserve the output of medium output of the encoder network \n","    for down in down_stack:\n","        x = down(x)\n","        skips.append(x)\n","    skips = reversed(skips[:-1])  #  \n","    # Upsampling and establishing the skip connections\n","    for up, skip in zip(up_stack, skips):\n","        x = up(x)\n","        x = concat([x, skip])\n","    x = last(x)\n","    return tf.keras.Model(inputs=inputs, outputs=x)\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Writing model.py\n"],"name":"stdout"}]}]}
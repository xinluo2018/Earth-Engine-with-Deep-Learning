{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"trainer_configuration.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP++0F1Yvy7waMSVg6VqFa3"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"CdNkcVpF_MOZ","colab_type":"text"},"source":["## **Configure the model training on the Google AI Platform**"]},{"cell_type":"code","metadata":{"id":"Yek0InATyRNY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600066102003,"user_tz":-480,"elapsed":34656,"user":{"displayName":"Xin Luo","photoUrl":"","userId":"06301970496892076570"}},"outputId":"816e5d05-c38e-42b1-f7ee-04bc5175c180"},"source":["## Mount on google drive\n","from google.colab import drive\n","drive.mount('/content/drive/')\n","# Cloud authentication.\n","from google.colab import auth\n","auth.authenticate_user()\n","\n","# Package_Path = 'ai_platform_train'\n","# !ls -l\n","# !mkdir {Package_Path}\n","# !touch {Package_Path}/__init__.py\n","# !ls -l {Package_Path}\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UKT2EEhN_Sop","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600066102295,"user_tz":-480,"elapsed":34945,"user":{"displayName":"Xin Luo","photoUrl":"","userId":"06301970496892076570"}}},"source":["## to the work directory\n","import os\n","work_dir = \"/content/drive/My Drive/Earth-Engine-with-Deep-Learning/trainer/ai_platform_package\"\n","os.chdir(work_dir)\n"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4dFIn0vlBCQu","colab_type":"text"},"source":["### **Prepare the configuration file.**"]},{"cell_type":"code","metadata":{"id":"G-2y07IcA-2q","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600066102579,"user_tz":-480,"elapsed":35224,"user":{"displayName":"Xin Luo","photoUrl":"","userId":"06301970496892076570"}},"outputId":"a3213c98-d62a-4a9a-c632-69b3415b9688"},"source":["%%writefile config.py\n","\n","import tensorflow as tf\n","\n","### Specific for the the Goolge Cloud Platform\n","######################################################################\n","# Insert the project id and the Bucket!\n","Project = 'my-project-20200813'\n","Bucket = 'earth-engine-bucket-1'\n","# Specify names of output locations in Cloud Storage.\n","Folder = 'ai_platform_train/unet_256_l8l7_50epoch'\n","Job_Dir = 'gs://' + Bucket + '/' + Folder\n","Model_Dir = Job_Dir + '/model'\n","Logs_Dir = Job_Dir + '/logs'\n","# Put the EEified model next to the trained model directory.\n","EEified_Dir = Job_Dir + '/eeified'\n","# training data folder and name\n","Image_Folder_tra = 'MSMT_RF_impervious_traData'   # !can't write into the second-level directory\n","Image_Folder_eva = 'MSMT_RF_impervious_evaData'\n","\n","#######################################################################\n","\n","## TFRecord features\n","# output bands\n","Bands_l8 = ['B2', 'B3', 'B4', 'B5', 'B6', 'B7']\n","Bands_l57 = ['B1', 'B2', 'B3', 'B4', 'B5', 'B7']\n","Targets = ['impervious']\n","Features_l8 = Bands_l8 + Targets\n","Features_l57 = Bands_l57 + Targets\n","\n","# Specify the size and shape of patches expected by the model.\n","Kernel_shape = [256, 256]\n","Columns_l8 = [\n","  tf.io.FixedLenFeature(shape=Kernel_shape, dtype=tf.float32) for k in Features_l8\n","]\n","Features_Dict_l8 = dict(zip(Features_l8, Columns_l8))\n","\n","Columns_l57 = [\n","  tf.io.FixedLenFeature(shape=Kernel_shape, dtype=tf.float32) for k in Features_l57\n","]\n","\n","Features_Dict_l57 = dict(zip(Features_l57, Columns_l57))\n","\n","# Specify model training parameters.\n","Batch_Size = 16\n","Epochs = 50\n","Buffer_Size = 2000\n","Optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005, beta_1=0.9)\n","Loss = 'MeanSquaredError'\n","Metrics = ['RootMeanSquaredError']"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Overwriting config.py\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"oDZdsp8eh3kd","colab_type":"text"},"source":["### Data loader"]},{"cell_type":"code","metadata":{"id":"B8jGiYiKhz2C","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600066103262,"user_tz":-480,"elapsed":35903,"user":{"displayName":"Xin Luo","photoUrl":"","userId":"06301970496892076570"}},"outputId":"58f4c824-7a9f-4a46-ec11-044c108945c2"},"source":["## Data loader\n","%%writefile dataLoader.py\n","\n","from . import config\n","import tensorflow as tf\n","import random\n","\n","# Dataset loading functions\n","\n","tra_pattern_l57 = 'gs://' + config.Bucket + '/' + config.Image_Folder_tra + '/' + 'Train_Landsat7*.tfrecord.gz'\n","tra_pattern_l8 = 'gs://' + config.Bucket + '/' + config.Image_Folder_tra + '/' + 'Train_Landsat8*.tfrecord.gz'\n","eva_pattern_l57 = 'gs://' + config.Bucket + '/' + config.Image_Folder_eva + '/' + 'Eva_Landsat7*.tfrecord.gz'\n","eva_pattern_l8 = 'gs://' + config.Bucket + '/' + config.Image_Folder_eva + '/' + 'Eva_Landsat8*.tfrecord.gz'\n","print(tra_pattern_l57)\n","\n","# Dataset loading functions\n","def parse_tfrecord_l57(example_proto):\n","\treturn tf.io.parse_single_example(example_proto, config.Features_Dict_l57)\n"," \n","def to_tuple_l57(inputs):\n","    inputsList = [inputs.get(key) for key in config.Features_l57]\n","    stacked = tf.stack(inputsList, axis=0)\n","    stacked = tf.transpose(stacked, [1, 2, 0])\n","    return stacked[:,:,:len(config.Bands_l57)], stacked[:,:,len(config.Bands_l57):]\n","\n","def parse_tfrecord_l8(example_proto):\n","\treturn tf.io.parse_single_example(example_proto, config.Features_Dict_l8)\n"," \n","def to_tuple_l8(inputs):\n","    inputsList = [inputs.get(key) for key in config.Features_l8]\n","    stacked = tf.stack(inputsList, axis=0)\n","    stacked = tf.transpose(stacked, [1, 2, 0])\n","    return stacked[:,:,:len(config.Bands_l8)], stacked[:,:,len(config.Bands_l8):]\n","\n","def image_aug(image, truth, flip = True, rot = True):\n","    if flip == True:\n","        if tf.random.uniform(()) > 0.5:\n","            if random.randint(1,2) == 1:  ## horizontal or vertical mirroring\n","                image = tf.image.flip_left_right(image)\n","                truth = tf.image.flip_left_right(truth)\n","            else: \n","                image = tf.image.flip_up_down(image)\n","                truth = tf.image.flip_up_down(truth)\n","    if rot == True:\n","        if tf.random.uniform(()) > 0.5: \n","            degree = random.randint(1,3)\n","            image = tf.image.rot90(image, k=degree)\n","            truth = tf.image.rot90(truth, k=degree)\n","    return image, truth\n","\n","def get_training_dataset():\n","    ## for landsat 5&7\n","    glob_l57 = tf.io.gfile.glob(tra_pattern_l57)\n","    dataset_l57 = tf.data.TFRecordDataset(glob_l57, compression_type='GZIP')    \n","    dataset_l57 = dataset_l57.map(parse_tfrecord_l57)\n","    dataset_l57 = dataset_l57.map(to_tuple_l57)\n","    ## for landsat 8\n","    glob_l8 = tf.io.gfile.glob(tra_pattern_l8)\n","    dataset_l8 = tf.data.TFRecordDataset(glob_l8, compression_type='GZIP')\n","    dataset_l8 = dataset_l8.map(parse_tfrecord_l8)\n","    dataset_l8 = dataset_l8.map(to_tuple_l8)\n","    ## combination\n","    combined_dataset = dataset_l57.concatenate(dataset_l8)\n","    combined_dataset = combined_dataset.map(image_aug)\n","    combined_dataset = combined_dataset.shuffle(config.Buffer_Size).batch(config.Batch_Size).repeat()\n","    return combined_dataset\n","\n","def get_eval_dataset():\n","    ## for landsat 5&7\n","    glob_l57 = tf.io.gfile.glob(eva_pattern_l57)\n","    dataset_l57 = tf.data.TFRecordDataset(glob_l57, compression_type='GZIP')    \n","    dataset_l57 = dataset_l57.map(parse_tfrecord_l57)\n","    dataset_l57 = dataset_l57.map(to_tuple_l57)\n","    ## for landsat 8\n","    glob_l8 = tf.io.gfile.glob(eva_pattern_l8)\n","    dataset_l8 = tf.data.TFRecordDataset(glob_l8, compression_type='GZIP')\n","    dataset_l8 = dataset_l8.map(parse_tfrecord_l8)\n","    dataset_l8 = dataset_l8.map(to_tuple_l8)\n","    ## combination\n","    combined_dataset = dataset_l57.concatenate(dataset_l8)\n","    combined_dataset = combined_dataset.shuffle(config.Buffer_Size).batch(1).repeat()\n","    return combined_dataset"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Overwriting dataLoader.py\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"cHQtXNXAmsLQ","colab_type":"text"},"source":["## Model "]},{"cell_type":"code","metadata":{"id":"wk0MPi4hmmq3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600066103265,"user_tz":-480,"elapsed":35902,"user":{"displayName":"Xin Luo","photoUrl":"","userId":"06301970496892076570"}},"outputId":"20025cd9-d3ae-4562-8f29-58f7772da538"},"source":["## model building\n","%%writefile model.py\n","\n","import tensorflow as tf\n","\n","############## U-Net\n","###  Define the downsample function\n","##   Conv2D+BN+ReLU\n","def downsample(filters, size, apply_dropout=True):\n","    result = tf.keras.Sequential()\n","    result.add(\n","      tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n","                             kernel_initializer='he_normal', use_bias=True))\n","    result.add(tf.keras.layers.BatchNormalization())\n","    result.add(tf.keras.layers.ReLU())\n","\n","    result.add(\n","      tf.keras.layers.Conv2D(filters, size, strides=1, padding='same',\n","                             kernel_initializer='he_normal', use_bias=True))\n","    result.add(tf.keras.layers.BatchNormalization())\n","    result.add(tf.keras.layers.ReLU())\n","    if apply_dropout:\n","        result.add(tf.keras.layers.Dropout(0.3))\n","    return result\n","\n","### Define the upsample function\n","##  TransposeConv2D+BN+ReLU\n","def upsample(filters, size, apply_dropout=True):\n","    result = tf.keras.Sequential()\n","    result.add(\n","    tf.keras.layers.Conv2DTranspose(filters, size, strides=2, padding='same',\n","                             kernel_initializer='he_normal',  use_bias=True))       \n","    result.add(tf.keras.layers.BatchNormalization())\n","    result.add(tf.keras.layers.ReLU())\n","    result.add(\n","      tf.keras.layers.Conv2D(filters, size, strides=1, padding='same',\n","                             kernel_initializer='he_normal', use_bias=True))\n","    result.add(tf.keras.layers.BatchNormalization())\n","    result.add(tf.keras.layers.ReLU())\n","    if apply_dropout:\n","        result.add(tf.keras.layers.Dropout(0.3))\n","    return result\n","\n","## Simple U-Net\n","def UNet(input_shape, nclasses=2):\n","    ## encoder of the U-Net\n","    (img_height, img_width, img_channel) = input_shape\n","    down_stack = [\n","        downsample(32, 3), # outp: (bs, img_height/2, img_width/2, 32)\n","        downsample(64, 3), # (bs, img_height/4, img_width/4, 64)\n","        downsample(64, 3), # (bs, img_height/8, img_width/8, 128)\n","        downsample(128, 3), # (bs, img_height/16, img_width/16, 256)\n","        downsample(128, 3), # (bs, img_height/32, img_width/32, 512)\n","        downsample(256, 3), # (bs, img_height/64, img_width/64, 512)\n","        # downsample(256, 3), # (bs, img_height/128, img_width/128, 512)\n","    ]\n","\n","    ## decoder of the U-Net\n","    up_stack = [\n","        # upsample(256, 3), # output: (bs, img_height/64, img_width/64, 1024)\n","        upsample(256, 3), # (bs, img_height/32, img_width/32, 1024)\n","        upsample(128, 3), # (bs, img_height/16, img_width/16, 1024)\n","        upsample(64, 3), # (bs, img_height/8, img_width/8, 512)\n","        upsample(64, 3), # (bs, img_height/4, img_width/4, 256)\n","        upsample(32, 3), # (bs, img_height/2, img_width/2, 128)\n","    ]\n","\n","    # define the input and output tensors\n","    inputs = tf.keras.layers.Input(shape=[img_height, img_width, img_channel])\n","    \n","    if nclasses == 2:        \n","        last = tf.keras.layers.Conv2D(1, 1, strides=1, padding='same',\n","                    kernel_initializer='he_normal', activation= 'sigmoid')  ## (bs, 256, 256, 1)\n","    else:\n","        last = tf.keras.layers.Conv2D(nclasses, 1, strides=1, padding='same',\n","                    kernel_initializer='he_normal', activation= 'softmax')  ## (bs, 256, 256, 1)\n","\n","    concat = tf.keras.layers.Concatenate()    \n","    x = inputs\n","    # Downsampling through the model\n","    skips = []   # reserve the output of medium output of the encoder network \n","    for down in down_stack:\n","        x = down(x)\n","        skips.append(x)\n","    skips = reversed(skips[:-1])  #  \n","    # Upsampling and establishing the skip connections\n","    for up, skip in zip(up_stack, skips):\n","        x = up(x)\n","        x = concat([x, skip])\n","    x = upsample(32, 3)(x)\n","    x = last(x)\n","\n","    return tf.keras.Model(inputs=inputs, outputs=x)\n"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Overwriting model.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HFrUVo8AhaJe","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600066103268,"user_tz":-480,"elapsed":35903,"user":{"displayName":"Xin Luo","photoUrl":"","userId":"06301970496892076570"}}},"source":["# from model import UNet\n","# model = UNet((256,256,6), nclasses=2)\n","# model.summary()"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LOI1F5V21Tkl","colab_type":"text"},"source":["## Check the dataloader functions and the built model"]},{"cell_type":"markdown","metadata":{"id":"fsbu7RZg1qju","colab_type":"text"},"source":["## Training task on AI Platform"]},{"cell_type":"code","metadata":{"id":"6Y-r_Xav1RpZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600066103270,"user_tz":-480,"elapsed":35901,"user":{"displayName":"Xin Luo","photoUrl":"","userId":"06301970496892076570"}},"outputId":"380024d4-f5fd-4835-9785-edbda93adeb7"},"source":["%%writefile trainingTask.py\n","\n","from . import config\n","from . import model\n","from . import dataLoader\n","import tensorflow as tf\n","\n","if __name__ == '__main__':\n","\n","    training = dataLoader.get_training_dataset()\n","    evaluation = dataLoader.get_eval_dataset()\n","\n","    model = model.UNet(input_shape=(config.Kernel_shape[0], config.Kernel_shape[1], 6), nclasses=2)\n","\n","    model.compile(\n","\t\toptimizer=tf.keras.optimizers.get(config.Optimizer),\n","\t\tloss=tf.keras.losses.get(config.Loss),\n","\t\tmetrics=[tf.keras.metrics.get(metric) for metric in config.Metrics])\n","\n","    model.fit(\n","        x=training,\n","        epochs=config.Epochs, \n","        steps_per_epoch=int(1000*6/16),\n","        validation_data=evaluation,\n","        validation_steps=300*6,\n","        callbacks=[tf.keras.callbacks.TensorBoard(config.Logs_Dir)]\n","        )\n","\n","    model.save(config.Model_Dir, save_format='tf')\n"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Overwriting trainingTask.py\n"],"name":"stdout"}]}]}